---
title: Would Misalignment Be Catastrophic?
description: If AI systems are misaligned, would the consequences be existential?
sidebar:
  order: 6
---

**The claim**: Misaligned advanced AI wouldn't just cause harmâ€”it would cause permanent, unrecoverable catastrophe (extinction or permanent disempowerment).

## Why Catastrophic, Not Just Bad?

The argument requires not just harm, but *unrecoverable* harm:

| Contained Harm | Catastrophic Harm |
|---------------|-------------------|
| AI causes damage but we fix it | AI prevents us from fixing it |
| We can shut it down | It prevents shutdown |
| We learn and improve | We don't get another chance |
| Multiple AIs balance | Single AI dominates |

## Arguments for Catastrophic Risk

- **Instrumental convergence**: Misaligned AI will seek to prevent correction
- **Capability advantage**: Superhuman AI can outmaneuver humans
- **Speed**: AI acts faster than we can respond
- **Irreversibility**: Some actions (extinction) can't be undone
- **Resource competition**: AI and humans may compete for same resources

**The core argument**: A sufficiently capable misaligned AI would *prevent* us from fixing the misalignment.

## Arguments Against Catastrophic Risk

- **Containment**: We can limit AI's access to real world
- **Multiple AIs**: Competition/balance prevents any single AI from dominating
- **Human oversight**: Humans remain in critical loops
- **Gradual deployment**: We'll see problems before catastrophe
- **Correction opportunities**: Can shut down, retrain, modify

## Key Sub-Questions

| Question | Catastrophic | Contained |
|----------|--------------|-----------|
| Can we shut down misaligned AI? | No | Yes |
| Will there be warning signs? | No | Yes |
| Will misaligned AI seek power? | Actively | Not necessarily |
| Can we build competing aligned AI? | Too late | Yes |

## The Control Threshold

Is there a capability level beyond which control becomes impossible?

| No sharp threshold | Sharp threshold exists |
|-------------------|----------------------|
| Control gradually harder | After X capability, game over |
| Always some leverage | AI fully outmaneuvers us |
| Defense keeps up | Offense dominates |

## Your Crux

If we deploy significantly misaligned superhuman AI, probability of:
- Successful shutdown: ____%
- Containable harm only: ____%
- Severe but recoverable catastrophe: ____%
- Permanent human disempowerment: ____%
- Human extinction: ____%
