---
title: Will AI Be Transformatively Powerful?
description: Will AI systems be capable enough to pose existential-level risks?
sidebar:
  order: 2
---

**The claim**: AI systems will become powerful enough to potentially end or permanently curtail human civilizationâ€”not just cause harm, but be truly transformative.

## What "Transformative" Means

| Level | Description | Existential Risk? |
|-------|-------------|-------------------|
| Narrow AI | Better than humans at specific tasks | No |
| Broad AI | Human-level across most cognitive tasks | Maybe |
| Superhuman AI | Exceeds humans at nearly everything | Yes, if misaligned |
| Superintelligence | Vastly exceeds humans | Almost certainly, if misaligned |

## Arguments for Transformative Capabilities

- No known ceiling on AI capabilities
- Intelligence is the source of human power over nature
- Superhuman AI could develop technology we can't imagine
- Recursive self-improvement could accelerate capabilities
- AI can run faster, copy itself, never sleep

**The core intuition**: "What happens when we're not the smartest things on the planet?"

## Arguments Against Transformative Risk

- Intelligence may have diminishing returns
- Physical constraints limit what any intelligence can do
- AI may remain tool-like, not agent-like
- "Superintelligence" may be an incoherent concept
- Current AI has fundamental limitations that may persist

## The Ceiling Question

| View | Claim |
|------|-------|
| No ceiling | AI capabilities will continue improving indefinitely |
| Human-level ceiling | AI will match but not greatly exceed human cognition |
| Physical ceiling | Even superintelligence is constrained by physics |
| Complexity ceiling | Some problems are intractable for any intelligence |

## Key Uncertainty

Even if AI becomes very capable, will it have the *kind* of capabilities that enable existential risk?

- Persuasion/manipulation at scale
- Cyber offense capabilities  
- Scientific/technological research
- Strategic planning over long time horizons
- Self-replication and resource acquisition

## Your Crux

What's your probability that AI will eventually:
- Match humans at most cognitive tasks: ____%
- Significantly exceed humans at strategic reasoning: ____%
- Be capable of taking over critical infrastructure: ____%
- Be able to prevent humans from shutting it down: ____%
