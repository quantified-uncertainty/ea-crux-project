---
title: Feedback Loop & Cascade Model
description: AI risk emerges from reinforcing feedback loops that can accelerate through critical thresholds.
tableOfContents: false
---

import CauseEffectGraph from '../../../../components/CauseEffectGraph';

<style>{`
  .breakout {
    margin-left: -300px;
    margin-right: -300px;
    width: calc(100% + 600px);
  }
  @media (max-width: 1400px) {
    .breakout {
      margin-left: -200px;
      margin-right: -200px;
      width: calc(100% + 400px);
    }
  }
  @media (max-width: 1100px) {
    .breakout {
      margin-left: -100px;
      margin-right: -100px;
      width: calc(100% + 200px);
    }
  }
  @media (max-width: 800px) {
    .breakout {
      margin-left: 0;
      margin-right: 0;
      width: 100%;
    }
  }
`}</style>

**Core thesis**: AI risk isn't static—it emerges from reinforcing feedback loops that can rapidly accelerate through critical thresholds. Understanding these dynamics is crucial for intervention timing.

<div class="breakout">
<CauseEffectGraph
  client:load
  height={1100}
  fitViewPadding={0.05}
  initialNodes={[
    {
      id: 'capability-growth',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Capability Growth Rate',
        description: 'Speed of AI capability improvement.',
        type: 'cause',
        confidence: 2.5,
        confidenceLabel: 'x/year (OOM)',
        details: 'Current growth ~2.5x per year on key benchmarks. Accelerating with scale.',
        relatedConcepts: ['Scaling', 'Progress', 'Benchmarks']
      }
    },
    {
      id: 'investment-rate',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Investment Rate',
        description: 'Capital flowing into AI.',
        type: 'cause',
        confidence: 100,
        confidenceLabel: '$B/year',
        details: 'Currently ~$100B/year globally. Doubling roughly every 2 years.',
        relatedConcepts: ['VC', 'Corporate', 'Government']
      }
    },
    {
      id: 'economic-value',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Economic Value Generated',
        description: 'Revenue and cost savings from AI.',
        type: 'intermediate',
        confidence: 500,
        confidenceLabel: '$B/year',
        details: 'Currently ~$500B/year value. Growing faster than investment.',
        relatedConcepts: ['Revenue', 'Productivity', 'Value']
      }
    },
    {
      id: 'talent-pool',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'AI Talent Pool',
        description: 'Cumulative skilled AI researchers.',
        type: 'cause',
        confidence: 50000,
        confidenceLabel: 'researchers',
        details: 'Currently ~50K serious AI researchers globally. Growing 15%/year.',
        relatedConcepts: ['Talent', 'PhDs', 'Engineers']
      }
    },
    {
      id: 'compute-stock',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Compute Stock',
        description: 'Cumulative training compute available.',
        type: 'cause',
        confidence: 26,
        confidenceLabel: 'log FLOP (total)',
        details: 'Current frontier training ~10^26 FLOP. Doubling every 6 months.',
        relatedConcepts: ['GPUs', 'TPUs', 'Datacenters']
      }
    },
    {
      id: 'ai-research-automation',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'AI Research Automation',
        description: 'Fraction of AI R&D done by AI.',
        type: 'intermediate',
        confidence: 0.15,
        confidenceLabel: 'fraction (0-1)',
        details: 'Currently ~15% of ML research tasks automated. Key acceleration trigger.',
        relatedConcepts: ['AutoML', 'AI scientists', 'Recursive']
      }
    },
    {
      id: 'deployment-pressure',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Deployment Pressure',
        description: 'Competitive pressure to deploy fast.',
        type: 'intermediate',
        confidence: 0.7,
        confidenceLabel: 'pressure (0-1)',
        details: 'Currently ~0.7. Intense competition drives rushed releases.',
        relatedConcepts: ['Competition', 'Time-to-market', 'Racing']
      }
    },
    {
      id: 'safety-investment',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Safety Investment',
        description: 'Resources devoted to AI safety.',
        type: 'cause',
        confidence: 1,
        confidenceLabel: '$B/year',
        details: 'Currently ~$1B/year. Growing but fraction declining.',
        relatedConcepts: ['Safety', 'Alignment', 'Funding']
      }
    },
    {
      id: 'safety-progress',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Safety Progress Rate',
        description: 'Speed of alignment advances.',
        type: 'intermediate',
        confidence: 1.2,
        confidenceLabel: 'x/year',
        details: 'Currently ~1.2x improvement per year. Slower than capabilities.',
        relatedConcepts: ['Alignment', 'Interpretability', 'Safety']
      }
    },
    {
      id: 'capability-safety-gap',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Capability-Safety Gap',
        description: 'Difference between capability and safety.',
        type: 'intermediate',
        confidence: 0.6,
        confidenceLabel: 'gap size (0-1)',
        details: 'Currently ~0.6 gap. Widening as capabilities outpace safety.',
        relatedConcepts: ['Gap', 'Differential', 'Race']
      }
    },
    {
      id: 'accident-rate',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'AI Accident Rate',
        description: 'Frequency of harmful AI incidents.',
        type: 'intermediate',
        confidence: 0.3,
        confidenceLabel: 'serious/year',
        details: 'Currently ~0.3 serious incidents/year. Rising with deployment.',
        relatedConcepts: ['Incidents', 'Failures', 'Harm']
      }
    },
    {
      id: 'public-concern',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Public Concern',
        description: 'Level of societal worry about AI.',
        type: 'intermediate',
        confidence: 0.45,
        confidenceLabel: 'level (0-1)',
        details: 'Currently ~0.45. Rising but not dominant issue yet.',
        relatedConcepts: ['Concern', 'Fear', 'Awareness']
      }
    },
    {
      id: 'regulatory-pressure',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Regulatory Pressure',
        description: 'Government push for AI regulation.',
        type: 'intermediate',
        confidence: 0.35,
        confidenceLabel: 'pressure (0-1)',
        details: 'Currently ~0.35. Growing but lagging tech progress.',
        relatedConcepts: ['Regulation', 'Policy', 'Government']
      }
    },
    {
      id: 'autonomy-level',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Deployed Autonomy Level',
        description: 'How agentic are deployed systems?',
        type: 'intermediate',
        confidence: 0.3,
        confidenceLabel: 'level (0-1)',
        details: 'Currently ~0.3 autonomy. Rising fast with agent frameworks.',
        relatedConcepts: ['Agency', 'Autonomy', 'Agents']
      }
    },
    {
      id: 'human-oversight',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Human Oversight Quality',
        description: 'Effectiveness of human supervision.',
        type: 'intermediate',
        confidence: 0.5,
        confidenceLabel: 'quality (0-1)',
        details: 'Currently ~0.5. Declining as systems become more complex.',
        relatedConcepts: ['Oversight', 'Supervision', 'Control']
      }
    },
    {
      id: 'concentration',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Power Concentration',
        description: 'AI capability concentration in few actors.',
        type: 'intermediate',
        confidence: 0.7,
        confidenceLabel: 'concentration (0-1)',
        details: 'Currently ~0.7 (top 3 labs dominate). Could enable lock-in.',
        relatedConcepts: ['Monopoly', 'Concentration', 'Power']
      }
    },
    {
      id: 'coordination-capacity',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Global Coordination',
        description: 'International AI governance capacity.',
        type: 'intermediate',
        confidence: 0.2,
        confidenceLabel: 'capacity (0-1)',
        details: 'Currently ~0.2. Very limited international coordination.',
        relatedConcepts: ['Treaties', 'Cooperation', 'UN']
      }
    },
    {
      id: 'threshold-recursive',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Recursive Improvement Threshold',
        description: 'Has AI crossed recursive improvement point?',
        type: 'intermediate',
        confidence: 0.1,
        confidenceLabel: 'P(crossed)',
        details: 'Currently ~10% likely crossed. Key phase transition point.',
        relatedConcepts: ['Recursion', 'Takeoff', 'Threshold']
      }
    },
    {
      id: 'threshold-deception',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Deception Capability Threshold',
        description: 'Can AI systematically deceive evaluators?',
        type: 'intermediate',
        confidence: 0.15,
        confidenceLabel: 'P(crossed)',
        details: 'Currently ~15% likely. Undermines all evaluation methods.',
        relatedConcepts: ['Deception', 'Sandbagging', 'Evals']
      }
    },
    {
      id: 'threshold-autonomy',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Autonomous Action Threshold',
        description: 'Can AI take consequential actions independently?',
        type: 'intermediate',
        confidence: 0.2,
        confidenceLabel: 'P(crossed)',
        details: 'Currently ~20% likely. Reduces human correction opportunities.',
        relatedConcepts: ['Agency', 'Independence', 'Autonomy']
      }
    },
    {
      id: 'controllability',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'System Controllability',
        description: 'Can humans effectively control AI systems?',
        type: 'intermediate',
        confidence: 0.6,
        confidenceLabel: 'controllability (0-1)',
        details: 'Currently ~0.6. Declining with capability and autonomy.',
        relatedConcepts: ['Control', 'Shutdown', 'Override']
      }
    },
    {
      id: 'cascade-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Cascade Risk',
        description: 'Risk of rapid system-wide failure.',
        type: 'intermediate',
        confidence: 0.15,
        confidenceLabel: 'probability',
        details: 'Currently ~15%. Interconnected systems create cascade potential.',
        relatedConcepts: ['Cascade', 'Contagion', 'Systemic']
      }
    },
    {
      id: 'lockin-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Lock-in Risk',
        description: 'Risk of irreversible bad outcomes.',
        type: 'intermediate',
        confidence: 0.2,
        confidenceLabel: 'probability',
        details: 'Currently ~20%. Concentration + autonomy enables lock-in.',
        relatedConcepts: ['Lock-in', 'Irreversibility', 'Permanence']
      }
    },
    {
      id: 'total-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Total Existential Risk',
        description: 'Combined probability of catastrophe.',
        type: 'effect',
        confidence: 0.15,
        confidenceLabel: 'P(catastrophe)',
        details: 'Current estimate ~15% risk. Driven by feedback loop dynamics.',
        relatedConcepts: ['X-risk', 'Catastrophe', 'Extinction']
      }
    }
  ]}
  initialEdges={[
    { id: 'e-invest-econ', source: 'investment-rate', target: 'economic-value', data: { impact: 0.50 } },
    { id: 'e-cap-econ', source: 'capability-growth', target: 'economic-value', data: { impact: 0.50 } },
    { id: 'e-econ-invest', source: 'economic-value', target: 'investment-rate', data: { impact: 0.60 }, style: { strokeDasharray: '5,5' }, label: 'LOOP' },
    { id: 'e-invest-cap', source: 'investment-rate', target: 'capability-growth', data: { impact: 0.35 } },
    { id: 'e-talent-cap', source: 'talent-pool', target: 'capability-growth', data: { impact: 0.30 } },
    { id: 'e-compute-cap', source: 'compute-stock', target: 'capability-growth', data: { impact: 0.35 } },
    { id: 'e-cap-auto', source: 'capability-growth', target: 'ai-research-automation', data: { impact: 0.70 } },
    { id: 'e-invest-auto', source: 'investment-rate', target: 'ai-research-automation', data: { impact: 0.30 } },
    { id: 'e-auto-cap', source: 'ai-research-automation', target: 'capability-growth', data: { impact: 0.50 }, style: { strokeDasharray: '5,5' }, label: 'LOOP' },
    { id: 'e-econ-pressure', source: 'economic-value', target: 'deployment-pressure', data: { impact: 0.60 } },
    { id: 'e-invest-pressure', source: 'investment-rate', target: 'deployment-pressure', data: { impact: 0.40 } },
    { id: 'e-invest-safety', source: 'investment-rate', target: 'safety-investment', data: { impact: 0.30 } },
    { id: 'e-concern-safety', source: 'public-concern', target: 'safety-investment', data: { impact: 0.40 } },
    { id: 'e-reg-safety', source: 'regulatory-pressure', target: 'safety-investment', data: { impact: 0.30 } },
    { id: 'e-safety-progress', source: 'safety-investment', target: 'safety-progress', data: { impact: 0.70 } },
    { id: 'e-talent-safetyprog', source: 'talent-pool', target: 'safety-progress', data: { impact: 0.30 } },
    { id: 'e-cap-gap', source: 'capability-growth', target: 'capability-safety-gap', data: { impact: 0.60 } },
    { id: 'e-safetyprog-gap', source: 'safety-progress', target: 'capability-safety-gap', data: { impact: 0.40 } },
    { id: 'e-gap-accident', source: 'capability-safety-gap', target: 'accident-rate', data: { impact: 0.50 } },
    { id: 'e-pressure-accident', source: 'deployment-pressure', target: 'accident-rate', data: { impact: 0.30 } },
    { id: 'e-autonomy-accident', source: 'autonomy-level', target: 'accident-rate', data: { impact: 0.20 } },
    { id: 'e-accident-concern', source: 'accident-rate', target: 'public-concern', data: { impact: 0.50 } },
    { id: 'e-cap-concern', source: 'capability-growth', target: 'public-concern', data: { impact: 0.30 } },
    { id: 'e-econ-concern', source: 'economic-value', target: 'public-concern', data: { impact: 0.20 } },
    { id: 'e-concern-reg', source: 'public-concern', target: 'regulatory-pressure', data: { impact: 0.60 } },
    { id: 'e-accident-reg', source: 'accident-rate', target: 'regulatory-pressure', data: { impact: 0.40 } },
    { id: 'e-cap-autonomy', source: 'capability-growth', target: 'autonomy-level', data: { impact: 0.50 } },
    { id: 'e-pressure-autonomy', source: 'deployment-pressure', target: 'autonomy-level', data: { impact: 0.50 } },
    { id: 'e-cap-oversight', source: 'capability-growth', target: 'human-oversight', data: { impact: 0.40 } },
    { id: 'e-autonomy-oversight', source: 'autonomy-level', target: 'human-oversight', data: { impact: 0.40 } },
    { id: 'e-safety-oversight', source: 'safety-progress', target: 'human-oversight', data: { impact: 0.20 } },
    { id: 'e-invest-conc', source: 'investment-rate', target: 'concentration', data: { impact: 0.40 } },
    { id: 'e-compute-conc', source: 'compute-stock', target: 'concentration', data: { impact: 0.35 } },
    { id: 'e-reg-conc', source: 'regulatory-pressure', target: 'concentration', data: { impact: 0.25 } },
    { id: 'e-concern-coord', source: 'public-concern', target: 'coordination-capacity', data: { impact: 0.40 } },
    { id: 'e-reg-coord', source: 'regulatory-pressure', target: 'coordination-capacity', data: { impact: 0.35 } },
    { id: 'e-conc-coord', source: 'concentration', target: 'coordination-capacity', data: { impact: 0.25 } },
    { id: 'e-auto-recursive', source: 'ai-research-automation', target: 'threshold-recursive', data: { impact: 0.60 } },
    { id: 'e-cap-recursive', source: 'capability-growth', target: 'threshold-recursive', data: { impact: 0.40 } },
    { id: 'e-cap-deception', source: 'capability-growth', target: 'threshold-deception', data: { impact: 0.60 } },
    { id: 'e-gap-deception', source: 'capability-safety-gap', target: 'threshold-deception', data: { impact: 0.40 } },
    { id: 'e-autonomy-thresh', source: 'autonomy-level', target: 'threshold-autonomy', data: { impact: 0.60 } },
    { id: 'e-cap-thresh', source: 'capability-growth', target: 'threshold-autonomy', data: { impact: 0.40 } },
    { id: 'e-deception-control', source: 'threshold-deception', target: 'controllability', data: { impact: 0.35 } },
    { id: 'e-autonomythresh-control', source: 'threshold-autonomy', target: 'controllability', data: { impact: 0.35 } },
    { id: 'e-oversight-control', source: 'human-oversight', target: 'controllability', data: { impact: 0.30 } },
    { id: 'e-control-cascade', source: 'controllability', target: 'cascade-risk', data: { impact: 0.40 } },
    { id: 'e-autonomy-cascade', source: 'autonomy-level', target: 'cascade-risk', data: { impact: 0.30 } },
    { id: 'e-recursive-cascade', source: 'threshold-recursive', target: 'cascade-risk', data: { impact: 0.30 } },
    { id: 'e-conc-lockin', source: 'concentration', target: 'lockin-risk', data: { impact: 0.35 } },
    { id: 'e-control-lockin', source: 'controllability', target: 'lockin-risk', data: { impact: 0.35 } },
    { id: 'e-coord-lockin', source: 'coordination-capacity', target: 'lockin-risk', data: { impact: 0.30 } },
    { id: 'e-cascade-total', source: 'cascade-risk', target: 'total-risk', data: { impact: 0.30 } },
    { id: 'e-lockin-total', source: 'lockin-risk', target: 'total-risk', data: { impact: 0.25 } },
    { id: 'e-gap-total', source: 'capability-safety-gap', target: 'total-risk', data: { impact: 0.25 } },
    { id: 'e-control-total', source: 'controllability', target: 'total-risk', data: { impact: 0.20 } }
  ]}
/>
</div>

## Key Feedback Loops

### Positive (Accelerating) Loops

| Loop | Mechanism | Current Status |
|------|-----------|----------------|
| **Investment → Value → Investment** | Economic success drives more investment | Active, strengthening |
| **AI → Research Automation → AI** | AI accelerates its own development | Emerging, ~15% automated |
| **Capability → Pressure → Deployment → Accidents → Concern** | Success breeds complacency | Active |
| **Autonomy → Complexity → Less Oversight → More Autonomy** | Systems escape human supervision | Early stage |

### Negative (Dampening) Loops

| Loop | Mechanism | Current Status |
|------|-----------|----------------|
| **Accidents → Concern → Regulation → Safety** | Harm triggers protective response | Weak, ~0.3 coupling |
| **Concern → Coordination → Risk Reduction** | Public worry enables cooperation | Very weak, ~0.2 |
| **Concentration → Regulation → Deconcentration** | Monopoly power triggers intervention | Not yet active |

## Critical Thresholds

The model identifies key **phase transition points** where dynamics fundamentally change:

| Threshold | Description | Current P(Crossed) | Consequence If Crossed |
|-----------|-------------|-------------------|------------------------|
| **Recursive Improvement** | AI can substantially improve itself | ~10% | Rapid capability acceleration |
| **Deception Capability** | AI can systematically deceive evaluators | ~15% | Safety evaluations unreliable |
| **Autonomous Action** | AI takes consequential actions without approval | ~20% | Reduced correction opportunities |
| **Oversight Failure** | Humans can't effectively supervise | ~30% | Loss of control |

## Stock Variables (Accumulations)

| Stock | Current Level | Trend | Implication |
|-------|---------------|-------|-------------|
| **Compute Stock** | 10^26 FLOP | Doubling/6mo | Capability foundation |
| **Talent Pool** | ~50K researchers | +15%/year | Persistent advantage |
| **Safety Debt** | ~0.6 gap | Widening | Accumulated risk |
| **Deployed Systems** | Billions of instances | Expanding | Systemic exposure |

## Cascade Dynamics

The model highlights how **local failures can propagate**:

1. **Technical cascade**: One system failure triggers others (interconnected infrastructure)
2. **Economic cascade**: AI-driven market crash → funding collapse → safety cuts
3. **Political cascade**: AI incident → regulation → race dynamics → accidents
4. **Trust cascade**: Deception discovered → all AI distrusted → coordination collapse

## Rate Variables

Key **velocities** that determine trajectory:

| Rate | Current Value | Danger Zone | Safe Zone |
|------|---------------|-------------|-----------|
| Capability growth | 2.5x/year | &gt;3x/year | &lt;1.5x/year |
| Safety progress | 1.2x/year | &lt;1x/year | &gt;2x/year |
| Deployment acceleration | +30%/year | &gt;50%/year | &lt;10%/year |
| Coordination building | +5%/year | &lt;0%/year | &gt;20%/year |

## Intervention Timing

The feedback loop structure suggests **when** interventions matter most:

| Phase | Characteristics | Key Interventions |
|-------|-----------------|-------------------|
| **Pre-threshold** | Loops weak, thresholds distant | Build safety capacity, coordination infrastructure |
| **Acceleration** | Positive loops strengthening | Slow capability growth, mandate safety investment |
| **Near-threshold** | Approaching phase transitions | Emergency coordination, possible pause |
| **Post-threshold** | New dynamics active | Depends on which threshold crossed |

## Full Variable List

This diagram simplifies the complete Feedback Loop Model:

**Positive Feedback Loops (13)**: Investment→value→investment, AI→research→AI, capability→pressure→deployment, success→talent→success, data→performance→data, autonomy→complexity→autonomy, speed→winner→speed, profit→compute→capability, deployment→learning→capability, concentration→resources→concentration, lock-in→stability→lock-in, capability→applications→funding, and more.

**Negative Feedback Loops (9)**: Accidents→regulation, concern→caution, competition→scrutiny, concentration→antitrust, capability→fear→restriction, deployment→saturation, talent→wages→barriers, profit→taxation, growth→resistance.

**Threshold/Phase Transition Nodes (11)**: Recursive improvement, deception capability, autonomous action, oversight failure, coordination collapse, economic dependency, infrastructure criticality, political capture, societal lock-in, existential event, recovery failure.

**Rate/Velocity Nodes (12)**: Capability growth rate, safety progress rate, deployment rate, investment acceleration, talent flow rate, compute expansion, autonomy increase, oversight degradation, coordination building, regulatory adaptation, concern growth, gap widening rate.

**Stock/Accumulation Nodes (8)**: Compute stock, talent pool, deployed systems, safety knowledge, institutional capacity, public awareness, coordination infrastructure, safety debt.

**Cascade/Contagion Nodes (7)**: Technical cascade, economic cascade, political cascade, trust cascade, infrastructure cascade, coordination cascade, recovery cascade.

**Critical Path Nodes (5)**: Time to recursive threshold, time to deception threshold, time to autonomy threshold, intervention window, recovery capacity.
