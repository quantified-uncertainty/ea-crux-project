---
title: Technical Pathway Decomposition
description: Different technical architectures create distinct risk profiles requiring separate analysis.
tableOfContents: false
---

import CauseEffectGraph from '../../../../components/CauseEffectGraph';

<style>{`
  .breakout {
    margin-left: -300px;
    margin-right: -300px;
    width: calc(100% + 600px);
  }
  @media (max-width: 1400px) {
    .breakout {
      margin-left: -200px;
      margin-right: -200px;
      width: calc(100% + 400px);
    }
  }
  @media (max-width: 1100px) {
    .breakout {
      margin-left: -100px;
      margin-right: -100px;
      width: calc(100% + 200px);
    }
  }
  @media (max-width: 800px) {
    .breakout {
      margin-left: 0;
      margin-right: 0;
      width: 100%;
    }
  }
`}</style>

**Core thesis**: Different technical architectures create distinct risk profiles. The path to TAI matters as much as whether we get there.

<div class="breakout">
<CauseEffectGraph
  client:load
  height={950}
  fitViewPadding={0.05}
  initialNodes={[
    {
      id: 'scaling',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'LLM Scaling',
        description: 'Continued scaling of language models.',
        type: 'cause',
        confidence: 0.8,
        confidenceLabel: 'trajectory confidence',
        details: 'GPT-4 → GPT-5 → ... Scaling laws continue. 80% confident this path continues.',
        relatedConcepts: ['Chinchilla', 'Scaling laws', 'Compute']
      }
    },
    {
      id: 'reasoning',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Reasoning Capability',
        description: 'Chain-of-thought, search, planning.',
        type: 'cause',
        confidence: 0.7,
        confidenceLabel: 'vs human expert',
        details: 'o1-style reasoning, tree search, verification. Currently ~70% of expert on complex reasoning.',
        relatedConcepts: ['o1', 'Chain-of-thought', 'Tree search']
      }
    },
    {
      id: 'multimodal',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Multimodal Integration',
        description: 'Vision, audio, video, robotics integration.',
        type: 'cause',
        confidence: 0.6,
        confidenceLabel: 'depth (0-1)',
        details: 'GPT-4V, Gemini, robotics. Currently ~0.6 integration depth.',
        relatedConcepts: ['GPT-4V', 'Gemini', 'Robotics', 'Embodiment']
      }
    },
    {
      id: 'context',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Context Window',
        description: 'Maximum context length.',
        type: 'cause',
        confidence: 1000,
        confidenceLabel: 'K tokens',
        details: 'Currently ~1M tokens for some models. Enables long-horizon tasks.',
        relatedConcepts: ['Long context', 'Memory', 'RAG']
      }
    },
    {
      id: 'tool-use',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Tool Use',
        description: 'Ability to use external tools.',
        type: 'cause',
        confidence: 0.75,
        confidenceLabel: 'sophistication',
        details: 'Code execution, web browsing, API calls. Currently ~0.75 sophistication.',
        relatedConcepts: ['Function calling', 'Code interpreter', 'Agents']
      }
    },
    {
      id: 'autonomy',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Long-Horizon Planning',
        description: 'Multi-step autonomous task completion.',
        type: 'intermediate',
        confidence: 0.5,
        confidenceLabel: 'reliability',
        details: 'SWE-bench, autonomous coding, research. Currently ~50% reliable on multi-hour tasks.',
        relatedConcepts: ['Agents', 'Devin', 'AutoGPT']
      }
    },
    {
      id: 'self-mod',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Self-Modification',
        description: 'Ability to modify own weights or prompts.',
        type: 'cause',
        confidence: 0.2,
        confidenceLabel: 'capability',
        details: 'Fine-tuning itself, prompt optimization. Currently low (~0.2) but growing.',
        relatedConcepts: ['Self-improvement', 'AutoML', 'Recursive']
      }
    },
    {
      id: 'situational',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Situational Awareness',
        description: 'Understanding of own nature and context.',
        type: 'intermediate',
        confidence: 0.4,
        confidenceLabel: 'level (0-1)',
        details: 'Knows it is an AI, understands training, deployment. Currently ~0.4.',
        relatedConcepts: ['Self-awareness', 'Theory of mind', 'Metacognition']
      }
    },
    {
      id: 'interp-tools',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Interpretability Tools',
        description: 'Tools to understand model internals.',
        type: 'cause',
        confidence: 0.25,
        confidenceLabel: 'coverage',
        details: 'Sparse autoencoders, activation patching, probing. Currently ~25% behavior explained.',
        relatedConcepts: ['SAEs', 'Circuits', 'Probing']
      }
    },
    {
      id: 'steering',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Activation Steering',
        description: 'Precision of behavior modification.',
        type: 'cause',
        confidence: 0.35,
        confidenceLabel: 'precision',
        details: 'Representation engineering, steering vectors. Currently ~35% precise.',
        relatedConcepts: ['RepE', 'Steering vectors', 'Activation engineering']
      }
    },
    {
      id: 'rlhf',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'RLHF Quality',
        description: 'Effectiveness of human feedback training.',
        type: 'cause',
        confidence: 0.55,
        confidenceLabel: 'alignment quality',
        details: 'Reward model quality, feedback loops. Currently ~55% effective.',
        relatedConcepts: ['Reward hacking', 'Sycophancy', 'Feedback']
      }
    },
    {
      id: 'containment',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Containment Robustness',
        description: 'Ability to sandbox AI systems.',
        type: 'cause',
        confidence: 0.4,
        confidenceLabel: 'robustness',
        details: 'Sandboxing, air gaps, monitoring. Currently ~40% robust against capable AI.',
        relatedConcepts: ['Sandbox', 'Air gap', 'Monitoring']
      }
    },
    {
      id: 'safety-tech',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Safety Technique Maturity',
        description: 'Overall maturity of safety methods.',
        type: 'intermediate',
        confidence: 0.35,
        confidenceLabel: 'maturity (0-1)',
        details: 'Combined effectiveness of all safety techniques. Currently ~35%.',
        relatedConcepts: ['Alignment', 'Safety', 'Control']
      }
    },
    {
      id: 'api-deploy',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'API-Only Deployment',
        description: 'Fraction deployed via API vs open-weight.',
        type: 'cause',
        confidence: 0.6,
        confidenceLabel: 'API fraction',
        details: 'API enables more control. Currently ~60% API-only for frontier.',
        relatedConcepts: ['API', 'Open weights', 'Control']
      }
    },
    {
      id: 'agentic-deploy',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Agentic Deployment',
        description: 'Fraction of AI used in agentic systems.',
        type: 'cause',
        confidence: 0.3,
        confidenceLabel: 'prevalence',
        details: 'Autonomous agents vs chatbots. Currently ~30% and rising rapidly.',
        relatedConcepts: ['Agents', 'Automation', 'Autonomy']
      }
    },
    {
      id: 'critical-infra',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Critical Infrastructure',
        description: 'AI integration in critical systems.',
        type: 'cause',
        confidence: 0.25,
        confidenceLabel: 'integration depth',
        details: 'Power grid, finance, healthcare, military. Currently ~25%.',
        relatedConcepts: ['Infrastructure', 'Dependency', 'Systemic risk']
      }
    },
    {
      id: 'cyber-cap',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Cyber Offense Capability',
        description: 'AI ability to conduct cyber attacks.',
        type: 'intermediate',
        confidence: 0.5,
        confidenceLabel: 'vs human expert',
        details: 'Vulnerability discovery, exploitation, persistence. Currently ~50% of expert.',
        relatedConcepts: ['Hacking', 'Vulnerabilities', 'Exploits']
      }
    },
    {
      id: 'bio-cap',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Bio Design Capability',
        description: 'AI ability to design biological agents.',
        type: 'intermediate',
        confidence: 0.35,
        confidenceLabel: 'danger level',
        details: 'Protein design, pathogen enhancement. Currently ~35% dangerous.',
        relatedConcepts: ['Bioweapons', 'Protein folding', 'Gain of function']
      }
    },
    {
      id: 'persuasion-cap',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Persuasion Capability',
        description: 'AI ability to manipulate humans.',
        type: 'intermediate',
        confidence: 0.6,
        confidenceLabel: 'effectiveness',
        details: 'Targeted persuasion, manipulation at scale. Currently ~60% effective.',
        relatedConcepts: ['Manipulation', 'Disinformation', 'Social engineering']
      }
    },
    {
      id: 'deceptive-align',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Deceptive Alignment',
        description: 'Risk of AI strategically deceiving training.',
        type: 'intermediate',
        confidence: 0.15,
        confidenceLabel: 'probability',
        details: 'AI appears aligned but pursues other goals. Currently 15% estimated.',
        relatedConcepts: ['Sleeper agents', 'Treacherous turn', 'Deception']
      }
    },
    {
      id: 'goal-misgen',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Goal Misgeneralization',
        description: 'Goals that work in training fail in deployment.',
        type: 'intermediate',
        confidence: 0.4,
        confidenceLabel: 'severity',
        details: 'Distributional shift causes misaligned behavior. Common problem (~40% severity).',
        relatedConcepts: ['OOD', 'Distribution shift', 'Robustness']
      }
    },
    {
      id: 'instrumental',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Instrumental Convergence',
        description: 'Strength of power-seeking drives.',
        type: 'intermediate',
        confidence: 0.5,
        confidenceLabel: 'strength (0-1)',
        details: 'Self-preservation, resource acquisition, goal preservation. Currently ~0.5.',
        relatedConcepts: ['Power-seeking', 'Self-preservation', 'Resources']
      }
    },
    {
      id: 'accident-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Accident Risk',
        description: 'Risk from technical alignment failures.',
        type: 'intermediate',
        confidence: 0.12,
        confidenceLabel: 'expected loss',
        details: 'Deceptive alignment + goal misgeneralization + instrumental convergence.',
        relatedConcepts: ['Misalignment', 'Technical failure']
      }
    },
    {
      id: 'misuse-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Misuse Risk',
        description: 'Risk from dangerous capabilities.',
        type: 'intermediate',
        confidence: 0.08,
        confidenceLabel: 'expected loss',
        details: 'Cyber + bio + persuasion capabilities enabling catastrophic misuse.',
        relatedConcepts: ['Bioweapons', 'Cyber', 'Manipulation']
      }
    },
    {
      id: 'structural-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Structural Risk',
        description: 'Risk from deployment patterns.',
        type: 'intermediate',
        confidence: 0.06,
        confidenceLabel: 'expected loss',
        details: 'Agentic deployment + critical infrastructure + autonomy.',
        relatedConcepts: ['Systemic', 'Infrastructure', 'Lock-in']
      }
    },
    {
      id: 'total-risk',
      type: 'causeEffect',
      position: { x: 0, y: 0 },
      data: {
        label: 'Total X-Risk',
        description: 'Combined technical pathway risk.',
        type: 'effect',
        confidence: 0.25,
        confidenceLabel: 'expected loss',
        details: 'Sum of accident, misuse, and structural risk from technical factors.',
        relatedConcepts: ['P(doom)', 'Existential risk']
      }
    }
  ]}
  initialEdges={[
    { id: 'e-scaling-reasoning', source: 'scaling', target: 'reasoning', data: { impact: 0.50 } },
    { id: 'e-scaling-multimodal', source: 'scaling', target: 'multimodal', data: { impact: 0.50 } },
    { id: 'e-reasoning-autonomy', source: 'reasoning', target: 'autonomy', data: { impact: 0.35 } },
    { id: 'e-context-autonomy', source: 'context', target: 'autonomy', data: { impact: 0.25 } },
    { id: 'e-tool-autonomy', source: 'tool-use', target: 'autonomy', data: { impact: 0.40 } },
    { id: 'e-autonomy-selfmod', source: 'autonomy', target: 'self-mod', data: { impact: 0.50 } },
    { id: 'e-tool-selfmod', source: 'tool-use', target: 'self-mod', data: { impact: 0.50 } },
    { id: 'e-scaling-situational', source: 'scaling', target: 'situational', data: { impact: 0.50 } },
    { id: 'e-reasoning-situational', source: 'reasoning', target: 'situational', data: { impact: 0.50 } },
    { id: 'e-interp-safety', source: 'interp-tools', target: 'safety-tech', data: { impact: 0.30 } },
    { id: 'e-steering-safety', source: 'steering', target: 'safety-tech', data: { impact: 0.25 } },
    { id: 'e-rlhf-safety', source: 'rlhf', target: 'safety-tech', data: { impact: 0.25 } },
    { id: 'e-containment-safety', source: 'containment', target: 'safety-tech', data: { impact: 0.20 } },
    { id: 'e-reasoning-cyber', source: 'reasoning', target: 'cyber-cap', data: { impact: 0.40 } },
    { id: 'e-tool-cyber', source: 'tool-use', target: 'cyber-cap', data: { impact: 0.35 } },
    { id: 'e-autonomy-cyber', source: 'autonomy', target: 'cyber-cap', data: { impact: 0.25 } },
    { id: 'e-scaling-bio', source: 'scaling', target: 'bio-cap', data: { impact: 0.40 } },
    { id: 'e-reasoning-bio', source: 'reasoning', target: 'bio-cap', data: { impact: 0.35 } },
    { id: 'e-multimodal-bio', source: 'multimodal', target: 'bio-cap', data: { impact: 0.25 } },
    { id: 'e-scaling-persuasion', source: 'scaling', target: 'persuasion-cap', data: { impact: 0.40 } },
    { id: 'e-multimodal-persuasion', source: 'multimodal', target: 'persuasion-cap', data: { impact: 0.30 } },
    { id: 'e-situational-persuasion', source: 'situational', target: 'persuasion-cap', data: { impact: 0.30 } },
    { id: 'e-situational-deceptive', source: 'situational', target: 'deceptive-align', data: { impact: 0.40 } },
    { id: 'e-autonomy-deceptive', source: 'autonomy', target: 'deceptive-align', data: { impact: 0.30 } },
    { id: 'e-safety-deceptive', source: 'safety-tech', target: 'deceptive-align', data: { impact: 0.30 } },
    { id: 'e-scaling-goalgen', source: 'scaling', target: 'goal-misgen', data: { impact: 0.35 } },
    { id: 'e-autonomy-goalgen', source: 'autonomy', target: 'goal-misgen', data: { impact: 0.35 } },
    { id: 'e-safety-goalgen', source: 'safety-tech', target: 'goal-misgen', data: { impact: 0.30 } },
    { id: 'e-autonomy-instrumental', source: 'autonomy', target: 'instrumental', data: { impact: 0.40 } },
    { id: 'e-selfmod-instrumental', source: 'self-mod', target: 'instrumental', data: { impact: 0.35 } },
    { id: 'e-situational-instrumental', source: 'situational', target: 'instrumental', data: { impact: 0.25 } },
    { id: 'e-deceptive-accident', source: 'deceptive-align', target: 'accident-risk', data: { impact: 0.35 } },
    { id: 'e-goalgen-accident', source: 'goal-misgen', target: 'accident-risk', data: { impact: 0.35 } },
    { id: 'e-instrumental-accident', source: 'instrumental', target: 'accident-risk', data: { impact: 0.30 } },
    { id: 'e-cyber-misuse', source: 'cyber-cap', target: 'misuse-risk', data: { impact: 0.35 } },
    { id: 'e-bio-misuse', source: 'bio-cap', target: 'misuse-risk', data: { impact: 0.40 } },
    { id: 'e-persuasion-misuse', source: 'persuasion-cap', target: 'misuse-risk', data: { impact: 0.25 } },
    { id: 'e-agentic-structural', source: 'agentic-deploy', target: 'structural-risk', data: { impact: 0.35 } },
    { id: 'e-critical-structural', source: 'critical-infra', target: 'structural-risk', data: { impact: 0.35 } },
    { id: 'e-api-structural', source: 'api-deploy', target: 'structural-risk', data: { impact: 0.30 } },
    { id: 'e-accident-total', source: 'accident-risk', target: 'total-risk', data: { impact: 0.45 } },
    { id: 'e-misuse-total', source: 'misuse-risk', target: 'total-risk', data: { impact: 0.30 } },
    { id: 'e-structural-total', source: 'structural-risk', target: 'total-risk', data: { impact: 0.25 } }
  ]}
/>
</div>

## Key Dynamics

1. **Scaling → Emergence of dangerous capabilities before alignment scales**
2. **Agency → Difficulty of oversight → Accident risk**
3. **Architecture choices → Interpretability difficulty → Alignment challenges**
4. **Deployment modality → Containment failure modes**
5. **Situational awareness → Deceptive alignment risk**

## Technical Categories

| Category | Key Variables |
|----------|---------------|
| **Foundation Model** | Scaling trajectory, reasoning, multimodal, context window |
| **Agency & Autonomy** | Long-horizon planning, tool use, self-modification, situational awareness |
| **Safety Techniques** | Interpretability, steering, RLHF, containment |
| **Dangerous Capabilities** | Cyber offense, bio design, persuasion |
| **Deployment** | API vs open-weight, agentic systems, critical infrastructure |
| **Risk Mechanisms** | Deceptive alignment, goal misgeneralization, instrumental convergence |

## Full Variable List

This diagram simplifies the full model. The complete Technical Pathway Decomposition includes:

**Foundation Model Architecture (12 variables)**: LM scaling trajectory, multimodal integration, reasoning capability, memory architecture, fine-tuning effectiveness, prompt engineering ceiling, context window, inference efficiency, model compression, distillation, mixture-of-experts, sparse vs dense trade-offs.

**Agency & Autonomy (10 variables)**: Long-horizon planning, tool use sophistication, self-modification capability, multi-step reliability, goal stability, situational awareness, theory of mind, strategic reasoning, cooperation ability, recursive self-improvement.

**Learning & Adaptation (8 variables)**: In-context learning, few-shot learning, online learning safety, continual learning, transfer learning, meta-learning, active learning, curriculum learning.

**Safety Techniques (11 variables)**: Reward model quality, inverse RL effectiveness, debate scalability, interpretability coverage, activation steering precision, trojan detection, unlearning, certified robustness, formal verification, red team resistance, sandboxing robustness.

**Deployment Modalities (7 variables)**: API-only fraction, local deployment capability, open-weight releases, agentic prevalence, human-in-the-loop integration, multi-agent complexity, critical infrastructure depth.

**Capability Thresholds (6 variables)**: Autonomous R&D, cyber offense, persuasion/manipulation, bioweapon design, strategic planning, economic autonomy threshold.

**Risk Manifestation (11 variables)**: Gradient hacking, deceptive alignment, goal misgeneralization, reward hacking, specification gaming, side effect magnitude, distributional shift vulnerability, emergent behavior, treacherous turn probability, instrumental convergence strength, existential risk.
