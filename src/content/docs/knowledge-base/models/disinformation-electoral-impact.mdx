---
title: Electoral Impact Assessment Model
description: Framework for estimating AI disinformation's marginal impact on elections
sidebar:
  order: 26
quality: 3
lastEdited: "2025-12-25"
---

import { DataInfoBox, Backlinks } from '../../../../components/wiki';

<DataInfoBox entityId="disinformation-electoral-impact" />

## Overview

AI dramatically lowers the cost of creating and distributing disinformation at scale. But does this translate to meaningful impact on election outcomes? This model provides a framework for estimating the marginal effect of AI-generated disinformation on electoral results and democratic processes.

**Core Question:** By how much can AI disinformation shift election results, and under what conditions?

## The Marginal Impact Problem

Elections are influenced by countless factors:
- Economic conditions
- Candidate quality
- Campaign spending
- Media coverage
- Debates and events
- Ground operations
- Traditional advertising
- **Disinformation (pre-AI)**
- **AI-Generated disinformation (new)**

**Challenge:** Isolating the marginal contribution of AI-enhanced disinformation from everything else.

## Impact Pathway Model

We can decompose the causal pathway from AI capability to electoral impact:

```
AI Capability
  ↓
Disinformation Volume & Quality
  ↓
Audience Exposure
  ↓
Belief Change
  ↓
Vote Choice Change
  ↓
Election Outcome Change
```

Each step has a probability/magnitude. The overall impact is the product of all steps.

### Step 1: AI → Disinformation Volume/Quality

**Pre-AI Disinformation Constraints:**
- Human effort required for each piece of content
- Limited personalization
- Detectable patterns (template-based)
- Cost: $1-10 per piece for quality content

**AI Enhancement:**
- Automated generation at massive scale
- Personalized to individual targets
- High quality, indistinguishable from organic content
- Cost: $0.001-0.01 per piece

**Multiplier Effect:**
- Volume increase: 100-1000x
- Quality increase: 1.5-3x (more convincing)
- Personalization increase: 10-100x (targeted messaging)

**Overall AI Impact on Content Creation:** ~150-3000x increase in effective disinformation output

**Confidence:** High. Well-documented in 2024 elections.

### Step 2: Volume/Quality → Exposure

Not all content reaches audiences. Social media algorithms, platform moderation, and user behavior filter content.

**Platform Moderation:**
- Platforms remove ~20-40% of detected disinformation
- AI-generated content currently detected at ~30-60% rate (falling)
- **Net effect:** 50-80% of AI disinformation reaches audiences (vs ~60-90% of human disinformation)

**Algorithmic Amplification:**
- Engaging content (often outrage-inducing disinformation) promoted
- AI-generated content can optimize for engagement
- **Multiplier:** 1.2-2x amplification vs. baseline

**Audience Reach:**
- Traditional disinformation: reaches 5-15% of target audience
- AI-personalized disinformation: reaches 10-30% of target audience (better targeting)

**Overall Exposure Multiplier (AI vs traditional):** 1.5-4x

**Confidence:** Medium. Platform algorithms are opaque; estimates based on disclosed data.

### Step 3: Exposure → Belief Change

How many people who see disinformation actually believe it?

**Baseline Belief Rates (Pre-AI):**
- Aligned with existing beliefs: 30-50% believe
- Counter to existing beliefs: 5-15% believe
- No prior opinion: 20-40% believe

**AI Enhancement Factors:**

**Personalization:** AI can tailor messaging to individual psychology
- Estimated increase in persuasiveness: 1.3-2x

**Multimodal Content:** Deepfakes, voice clones more convincing than text
- Estimated increase for video/audio: 1.5-2.5x vs text

**Repetition at Scale:** Multiple exposures via different "sources" (all AI)
- Estimated increase per additional exposure: 1.2x (up to 3-4 exposures)

**Overall Belief Change Multiplier (AI vs traditional):** 2-6x depending on content type and targeting

**Confidence:** Low-Medium. Limited experimental data. Based on persuasion research and preliminary studies.

### Step 4: Belief Change → Vote Choice Change

Not all belief changes translate to vote switching.

**Baseline Vote Impact (pre-AI disinformation):**
- Partisans rarely switch: 1-3% affected
- Swing voters more susceptible: 10-20% affected
- Low-information voters most susceptible: 15-30% affected

**Election Type Matters:**
- Presidential elections: Voters have strong priors, hard to shift
- Local elections: Lower information, easier to influence
- Ballot initiatives: Voters often uncertain, highly influenceable

**AI Disinformation Vote Impact:**
Assuming AI increases belief change by 2-6x (Step 3):
- Partisans: 2-8% affected (low end—beliefs don't translate to switching)
- Swing voters: 15-35% affected
- Low-info voters: 25-50% affected

**Weighted Average (typical electorate):**
- ~15% swing voters
- ~30% low-info voters
- ~55% strong partisans

**Overall Vote Impact:** 5-15% of exposed population might shift vote due to AI disinformation

**Confidence:** Low. Vote switching is multi-causal; attribution difficult.

### Step 5: Vote Change → Outcome Change

Finally, how many votes need to shift to change election results?

**Close Elections:**
- 2020 U.S. Presidential: Decided by ~44,000 votes across 3 states (~0.03% of total votes)
- Many congressional races decided by 1-3%
- **Close elections highly vulnerable to small shifts**

**Landslide Elections:**
- 10+ point margins require massive shifts to overturn
- AI disinformation unlikely to swing

**Quantitative Model:**

Assume:
- Close election (within 3%)
- AI disinformation reaches 30% of electorate
- Of those, 10% shift votes
- Overall vote shift: 3%

**Result:** Enough to flip a close election.

## Case Study Analysis

### 2024 Elections: The "AI Election" That Wasn't?

Despite being called the "AI election year," post-election analysis found limited evidence of decisive AI disinformation impact.

**Why the limited impact?**

**Possible Explanations:**

1. **Detection Worked:** Platform moderation caught enough AI content to limit spread
   - **Evidence:** Multiple platforms reported removing AI-generated campaigns
   - **Counter-evidence:** Much went undetected

2. **Audience Skepticism:** Voters increasingly aware of AI manipulation, more skeptical
   - **Evidence:** Increased media literacy campaigns
   - **Counter-evidence:** Most voters unaware of specific AI threats

3. **Cheap Fakes More Effective:** Simple edited videos outperformed sophisticated AI (7:1 ratio per News Literacy Project)
   - **Evidence:** Well-documented
   - **Implication:** Quality may matter less than simplicity

4. **Existing Polarization Dominates:** Voters already so polarized that marginal disinformation doesn't matter
   - **Evidence:** Historically high partisan loyalty
   - **Implication:** AI disinformation adds noise, not signal

5. **Measurement Problem:** Impact exists but is undetectable amid other factors
   - **Evidence:** Close races in swing states consistent with small AI impact
   - **Problem:** Can't prove counterfactual

**Most Likely:** Combination of #3, #4, and #5. AI disinformation had some impact but was not decisive in 2024.

### Slovakia 2023: Deepfake Audio Incident

**Event:** Audio deepfake of liberal party leader discussing vote rigging surfaced days before election
**Result:** Liberal party suffered upset loss
**Attribution:** Unclear if deepfake was decisive

**Analysis:**
- Timing (just before election) maximized impact, minimized correction time
- Topic (vote rigging) highly salient and credible to some voters
- Close race amplified marginal effects

**Estimated Impact:** Possibly 1-3% vote shift, potentially decisive in close race

**Lessons:**
- Timing matters enormously
- Topic credibility affects impact
- Close races vulnerable to small effects

### Taiwan 2024: Documented AI Influence Campaign

**Event:** Microsoft documented China-based AI-generated deepfakes targeting Taiwan election
**Result:** Unclear impact on outcome
**Characteristics:** First confirmed state-actor use of AI in foreign election

**Analysis:**
- Detected and publicized before election (reduced impact)
- Taiwan electorate somewhat prepared for Chinese interference
- Content quality varied (some obvious, some convincing)

**Estimated Impact:** &lt;1% vote shift, not decisive

**Lessons:**
- Attribution and publicity can reduce impact
- Prepared electorates more resilient

## Quantitative Impact Estimates

### Model 1: Multiplicative Probability

```
P(AI flips election) = P(close race) × P(AI campaign) × P(reaches voters) × P(shifts votes) × P(shift is decisive)

Where:
P(close race) = 0.15-0.30 (varies by election type)
P(AI campaign) = 0.50-0.90 (becoming common)
P(reaches voters) = 0.20-0.50 (platform moderation, virality)
P(shifts votes) = 0.05-0.15 (small persuasion effect)
P(shift is decisive) = 0.10-0.30 (in close race context)
```

**Result:** P(AI flips election) = 0.0015 to 0.054 (0.15% to 5.4%)

**Interpretation:** In any given election, AI disinformation has a ~0.2-5% chance of being decisive.

Over many elections (50+ major races in a year), **AI disinformation likely flips 1-3 elections annually** (current state).

**Confidence:** Very low. Enormous uncertainty in each parameter.

### Model 2: Vote Margin Approach

**Baseline Assumptions:**
- 100 million voters
- 50-50 race
- 30% exposed to AI disinformation
- 5% of exposed shift votes
- 1.5 million vote shift (1.5% of total)

**In close elections (decided by &lt;1%):** AI disinformation likely decisive

**In moderate elections (3-5% margin):** AI disinformation possibly influential but not clearly decisive

**In landslide elections (>7% margin):** AI disinformation unlikely decisive

**Implication:** ~20-30% of elections are close enough that AI disinformation could plausibly be decisive.

## Factors Moderating Impact

### Increasing AI Impact

1. **Targeting Sophistication:** Better micro-targeting increases efficiency
2. **Multimodal Content:** Video/audio more persuasive than text
3. **Coordination:** Multiple AI campaigns from different sources reinforce messaging
4. **Erosion of Trust:** As authentic media becomes suspect, all information becomes equally (un)reliable
5. **Authoritarian Backing:** State-sponsored campaigns have more resources and persistence

### Decreasing AI Impact

1. **Platform Countermeasures:** Detection, labeling, removal
2. **Media Literacy:** Educated populations more skeptical
3. **Provenance Systems:** C2PA and similar make authentic content verifiable
4. **Partisan Polarization:** Voters so entrenched that persuasion is difficult
5. **Saturation:** So much disinformation that all becomes noise

## Trajectory Projections

### 2024-2026: Early Impact Phase

**Characteristics:**
- AI disinformation common but detectable
- Platforms implementing countermeasures
- Electorate beginning to adapt
- **Estimated impact:** 1-3% of close elections flipped

### 2026-2028: Escalation Phase

**Characteristics:**
- AI-generated content becomes harder to detect
- Personalization improves (better targeting)
- More actors deploy AI campaigns
- Public awareness increases but so does volume
- **Estimated impact:** 3-8% of close elections flipped

### 2028-2030: Saturation or Adaptation

**Two Possible Paths:**

**Path A: Saturation (40% probability)**
- So much disinformation that voters tune out
- All information treated as equally suspect
- Impact paradoxically decreases as volume increases
- **Estimated impact:** 2-5% of elections (impact declines)

**Path B: Sophistication Wins (60% probability)**
- Personalized, multimodal AI content highly effective
- Detection fails to keep pace
- Provenance systems not widely adopted
- **Estimated impact:** 10-20% of close elections flipped

## Systemic Democratic Effects

Beyond individual elections, AI disinformation affects democratic health:

**Trust Erosion:**
- Even if specific election impacts are small, aggregate trust in media declines
- "Liar's dividend" makes all evidence deniable
- Democratic deliberation requires shared reality—this breaks down

**Measured Impact:**
- Trust in media: Declining 3-5% annually (accelerating)
- Belief in election integrity: Declining 2-4% annually
- Political polarization: Increasing (AI contribution unclear but likely 10-30%)

**These systemic effects may matter more than vote margins in individual elections.**

## Policy Implications

### If Impact is Currently Low (&lt;2% of elections)

**Interpretation:** Current countermeasures working; worry may be overblown

**Recommended Actions:**
- Maintain current platform policies
- Monitor for increasing impact
- Continue media literacy efforts
- Avoid over-regulation that might harm free speech

### If Impact is Moderate (2-8% of elections)

**Interpretation:** Significant threat but manageable with effort

**Recommended Actions:**
- Strengthen platform detection and removal
- Mandate provenance systems (C2PA)
- Increase funding for election security
- International cooperation on attribution and consequences

### If Impact is High (>10% of elections)

**Interpretation:** Crisis-level threat to democratic integrity

**Recommended Actions:**
- Emergency measures: possible temporary restrictions on AI-generated political content
- Mandatory authentication for all political advertising
- Dramatic increase in election security budgets
- Consider election reforms (longer voting periods to allow fact-checking)

## Model Limitations

1. **Counterfactual Problem:** Can't know what would have happened without AI disinformation

2. **Multi-Causality:** Elections influenced by dozens of factors; isolating AI effect nearly impossible

3. **Detection Bias:** Only measuring detected campaigns; most sophisticated may go unnoticed

4. **Heterogeneity:** Impact varies wildly by election type, electorate, and context

5. **Rapid Change:** Model parameters shifting quickly as technology and countermeasures evolve

## Key Debates

**Did AI "Break" 2024 Elections?** Research suggests no, but measurement problems make this uncertain. Absence of evidence is not evidence of absence.

**What Matters More: Individual Elections or Systemic Trust?** Even if AI doesn't flip many elections, erosion of epistemic commons might be the bigger harm.

**Can Democracy Survive in an Era of Undetectable Disinformation?** Pessimists say no; optimists argue humans have adapted to information threats before.

## Related Models

- [Disinformation Detection Arms Race](/knowledge-base/models/disinformation-detection-race/) - Can we detect it at all?
- [Deepfakes Authentication Crisis](/knowledge-base/models/deepfakes-authentication-crisis/) - Visual media authenticity

## Sources

- Stanford HAI. "The Disinformation Machine: How Susceptible Are We to AI Propaganda?" (2024)
- News Literacy Project. "Cheap Fakes vs. AI in 2024 Elections" analysis
- Microsoft Threat Intelligence. "Taiwan Election Interference Report" (2024)
- Academic literature on campaign persuasion effects
- Post-election analyses from multiple jurisdictions

## Related Pages

<Backlinks client:load entityId="disinformation-electoral-impact" />
