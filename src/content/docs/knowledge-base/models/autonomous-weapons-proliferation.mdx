---
title: LAWS Proliferation Model
description: Timeline and dynamics of lethal autonomous weapons spreading globally
sidebar:
  order: 24
quality: 3
lastEdited: "2025-12-25"
ratings:
  novelty: 3
  rigor: 4
  actionability: 4
  completeness: 4
---

import { DataInfoBox, Backlinks } from '../../../../components/wiki';

<DataInfoBox entityId="autonomous-weapons-proliferation" ratings={frontmatter.ratings} />

## Overview

Lethal Autonomous Weapons Systems (LAWS) are spreading from advanced militaries to a widening circle of state and non-state actors. This model analyzes the diffusion dynamics, projects timelines for different proliferation milestones, and examines implications for global security.

**Central Question:** How fast are autonomous weapons proliferating, and can proliferation be controlled?

## Proliferation Stages

### Stage 1: Great Power Development (2015-2023)
**Actors:** U.S., China, Russia, Israel
**Capabilities:** Advanced AI-enabled weapons, substantial autonomy
**Deployment:** Limited operational use, extensive R&D
**Status:** Complete

### Stage 2: Regional Power Adoption (2020-2026)
**Actors:** Turkey, Iran, UK, France, India, South Korea
**Capabilities:** Mid-tier autonomous systems, often licensed or adapted
**Deployment:** Battlefield testing, limited conflicts
**Status:** Ongoing (60-80% complete)

### Stage 3: Widespread State Access (2024-2030)
**Actors:** 30-50 nations
**Capabilities:** Commercial and exported LAWS, varying sophistication
**Deployment:** Routine military integration
**Status:** Emerging (20-40% complete)

### Stage 4: Non-State Actor Access (2026-2032)
**Actors:** Well-funded militant groups, terrorist organizations, criminal networks
**Capabilities:** Commercial drones with autonomous targeting, DIY systems
**Deployment:** Assassinations, terrorism, targeted attacks
**Status:** Early signs (5-10% complete)

### Stage 5: Mass Availability (2030+)
**Actors:** Individual actors with technical skills
**Capabilities:** Consumer hardware modified for autonomous lethality
**Deployment:** Lone-wolf attacks, vigilantism
**Status:** Not yet reached (&lt;5%)

## Current Proliferation State (2025)

### Nations with Documented LAWS Programs

**Tier 1 (Advanced, Deployed):**
- **United States:** Loyal Wingman drones, Autonomous Air Defense
- **China:** Extensive autonomous drone programs, swarming capabilities
- **Israel:** Harpy/Harop loitering munitions, autonomous defense systems
- **Turkey:** Kargu-2, STM Kargu (documented autonomous use in Libya)
- **Russia:** Claimed autonomous systems (verification difficult)

**Tier 2 (Developing, Testing):**
- **Ukraine:** AI-enabled FPV drones, autonomous targeting (4M annual production capacity)
- **Iran:** Shahed drones with increasing autonomy
- **UK, France, Germany:** Collaborative European programs
- **South Korea:** DMZ autonomous sentry guns
- **India:** Development programs

**Tier 3 (Early Research/Procurement):**
- 20-30 additional nations with announced programs

**Total:** ~40-50 nations with some level of autonomous weapons capability

### Technology Diffusion Pathways

**1. Direct Military Development**
Nations with advanced AI capabilities develop indigenous systems
- High cost, high capability
- Examples: U.S., China

**2. Technology Transfer & Sales**
Advanced nations sell or license systems to allies
- Medium cost, high capability
- Examples: Israeli systems sold internationally

**3. Commercial Adaptation**
Military adaptation of commercial drone/AI technology
- Low cost, medium capability
- Examples: Ukraine's modified commercial drones

**4. Reverse Engineering**
Captured or crashed systems reverse-engineered
- Medium cost, medium capability
- Examples: Iran's drone programs

**5. Open-Source AI + Commercial Hardware**
Public AI models combined with readily available drones
- Very low cost, low-medium capability
- Examples: DIY autonomous targeting systems

## Proliferation Speed Analysis

### Historical Comparison: Nuclear Weapons

| Milestone | Years Since First Use |
|-----------|----------------------|
| 1st nation (U.S.) | 0 (1945) |
| 2nd nation (USSR) | 4 years (1949) |
| 3rd nation (UK) | 7 years (1952) |
| 5 nations | 19 years (1964) |
| 9 nations | ~63 years (2006, North Korea) |

**Proliferation Rate:** Very slow. Technical barriers high, materials rare, detection possible.

### LAWS Proliferation Timeline

| Milestone | Years Since First Development |
|-----------|-------------------------------|
| 1st nation (contested, ~2017) | 0 |
| 5 nations | ~3-5 years (2020-2022) |
| 10 nations | ~5-7 years (2022-2024) |
| 20 nations | ~7-10 years (2024-2027, projected) |
| 50 nations | ~10-15 years (2027-2032, projected) |

**Proliferation Rate:** Much faster than nuclear weapons. Why?

### Why LAWS Proliferate Faster

**1. No Rare Materials**
- Nuclear weapons require enriched uranium or plutonium (difficult to obtain)
- LAWS require computer chips, sensors, software (commercially available)

**2. Dual-Use Technology**
- Nuclear enrichment has limited civilian use
- AI and drones have vast civilian applications (delivery, photography, agriculture)
- **Cannot restrict LAWS components without crippling civilian economy**

**3. Lower Cost**
- Nuclear weapons program: $billions to $trillions
- Advanced autonomous drone: $thousands to $millions
- **3-6 orders of magnitude cheaper**

**4. Easier to Conceal**
- Nuclear facilities detectable by satellites, radiation signatures
- LAWS development indistinguishable from civilian AI/drone work
- **Verification nearly impossible**

**5. Knowledge Diffusion**
- Nuclear weapons knowledge closely guarded
- AI research published openly, models open-sourced
- **Information flows freely**

## Quantitative Proliferation Model

### Diffusion Curve Projection

Using an epidemiological-style diffusion model (similar to Rogers' Innovation Adoption):

```
N(t) = K / (1 + exp(-r(t - t₀)))

Where:
N(t) = Number of nations with LAWS at time t
K = Total potential adopters (~180 nations)
r = Proliferation rate (how fast it spreads)
t₀ = Inflection point (when adoption accelerates)
```

**Parameters:**
- K = 120 (realistic potential adopters, excluding smallest nations)
- r = 0.35 (faster than most military tech, slower than purely civilian tech)
- t₀ = 2025 (inflection point where adoption accelerates)

**Projections:**

| Year | Nations with LAWS | % of Potential Adopters |
|------|-------------------|------------------------|
| 2020 | ~5 | 4% |
| 2025 | ~20 | 17% |
| 2030 | ~60 | 50% |
| 2035 | ~95 | 79% |
| 2040 | ~110 | 92% |

**Interpretation:** By 2030, half of all nations capable of fielding LAWS will have them. By 2035, near-universal among militaries.

### Non-State Actor Timeline

Harder to model, but using analogies to other weapon proliferation:

**Commercial Drone Weaponization History:**
- 2014: ISIS first weaponized commercial drones (simple grenades)
- 2017: Sophisticated drone swarms used by militants
- 2020: Assassination attempts using armed drones
- **Progression:** ~6 years from first use to significant threat

**Autonomous Weapons Progression Estimate:**
- 2020: First autonomous targeting by militant groups (limited)
- 2025: Documented use in assassinations/attacks (emerging)
- 2028-2030: Regular use by well-funded organizations (projected)
- 2032-2035: Accessible to smaller groups with technical expertise (projected)

**Key Uncertainty:** Will lone actors gain access? Depends on:
- Open-source AI progress
- Commercial drone capabilities
- Legal restrictions on sales

## Proliferation Control Mechanisms

### What Has Been Tried

**1. Export Controls**
- Wassenaar Arrangement covers some drone technology
- **Effectiveness:** Low. Dual-use nature makes enforcement difficult

**2. International Norms**
- UN Conventions on Certain Conventional Weapons (CCW) discussions ongoing
- Campaign to Stop Killer Robots advocacy
- **Effectiveness:** Minimal. No binding agreement reached

**3. Corporate Self-Regulation**
- Some AI labs refuse military applications
- Drone manufacturers implement geofencing
- **Effectiveness:** Limited. State programs unaffected

**4. Technical Safeguards**
- "Kill switches" or remote disable features
- Geofencing prevents operation in certain areas
- **Effectiveness:** Moderate for commercial systems, bypassed by state/military actors

### What Might Work

**1. Meaningful Human Control Standards**
- International agreement requiring human decision for lethal action
- **Feasibility:** Low. Difficult to verify, major powers opposed
- **Impact if Implemented:** High. Would prevent full autonomy

**2. AI Model Export Controls**
- Restrict export of AI models capable of autonomous targeting
- **Feasibility:** Low. Models can be recreated, knowledge diffuses
- **Impact if Implemented:** Low. Delay of 1-2 years at most

**3. Component-Level Restrictions**
- Limit sale of specific sensor/processor combinations
- **Feasibility:** Very Low. Components have vast civilian uses
- **Impact if Implemented:** Minimal. Workarounds readily available

**4. Attribution Mechanisms**
- Technical means to trace LAWS use back to source
- **Feasibility:** Medium. Like nuclear forensics
- **Impact if Implemented:** Medium. Enables accountability and deterrence

**5. Defensive Technology Focus**
- International cooperation on counter-LAWS technology
- **Feasibility:** High. Defensive cooperation more acceptable
- **Impact if Implemented:** Medium. Reduces LAWS effectiveness

**6. Stigmatization Campaign**
- Create strong international norm against autonomous weapons
- Analogous to landmine or cluster munition campaigns
- **Feasibility:** Medium. Already underway but facing resistance
- **Impact if Implemented:** Medium-High if successful, but major powers may not join

## Proliferation Scenarios

### Scenario 1: Uncontrolled Proliferation (40% probability)

**Trajectory:**
- No international agreement reached
- Technology diffuses rapidly
- By 2030, 60+ nations have advanced LAWS
- By 2035, non-state actors routinely use autonomous weapons

**Consequences:**
- Dramatic increase in targeted killings
- Assassination becomes accessible and scalable
- Authoritarian regimes use LAWS for domestic repression
- Terrorist attacks become more lethal
- Arms race dynamics intensify

**Likelihood:** High. Current trajectory without major policy shift.

### Scenario 2: Partial Control (35% probability)

**Trajectory:**
- Some international norms established but not universal
- Major powers (U.S., China, Russia) abstain or maintain loopholes
- Smaller nations and non-state actors somewhat constrained
- Technology still diffuses but more slowly

**Consequences:**
- Two-tier system: advanced militaries with LAWS, others restricted
- Black markets develop for autonomous weapons
- Norms reduce but don't eliminate proliferation
- Periodic violations and enforcement challenges

**Likelihood:** Medium. Most realistic "compromise" outcome.

### Scenario 3: Effective Control (15% probability)

**Trajectory:**
- Strong international treaty with major power buy-in
- Meaningful human control requirements adopted globally
- Robust verification and enforcement
- Proliferation slowed significantly

**Consequences:**
- LAWS development focuses on defensive systems
- Human-in-the-loop remains standard
- Slower military AI adoption but more controlled
- Reduces autonomous weapons risks substantially

**Likelihood:** Low. Requires major diplomatic breakthrough.

### Scenario 4: Defensive Technology Victory (10% probability)

**Trajectory:**
- Counter-LAWS technology advances faster than LAWS
- Autonomous weapons become ineffective
- Proliferation continues but systems are easily defeated
- Military value diminishes

**Consequences:**
- LAWS become niche weapons rather than dominant
- Arms race shifts to counter-LAWS measures
- Reduced risk from proliferation because weapons less effective

**Likelihood:** Low. Historically, offense-defense races don't typically end with defense winning decisively.

## Risk Implications by Proliferation Level

### Current State (~20 nations): Manageable Risk
- Limited number of actors
- Mostly state-controlled
- International dialogue still possible

### 2030 Projection (~60 nations): Elevated Risk
- Widespread but still primarily state actors
- Non-state access beginning
- Norms harder to establish
- Regional conflicts may feature LAWS prominently

### 2035+ Projection (~95 nations, non-state access): High Risk
- Near-universal state proliferation
- Non-state actors have reliable access
- Assassination and terrorism capabilities widely distributed
- Control effectively impossible
- "Slaughterbots" scenario becomes plausible

## Key Uncertainties

**1. AI Capability Progress Rate**
Faster AI progress → faster proliferation → earlier high-risk scenarios

**2. International Governance Success**
Unlikely but would dramatically alter trajectories

**3. Public Opinion & Democracy**
Democratic publics might demand restrictions (or might support military advantage)

**4. Offensive/Defensive Technology Balance**
If defense dominates, proliferation matters less

**5. Major Conflict Catalyst**
High-profile LAWS incident could trigger rapid norm formation or accelerated proliferation

## Policy Recommendations

### For High Proliferation Probability (~75%)

**Accept proliferation is likely, focus on:**
- Damage limitation (defensive tech, resilience)
- Attribution capabilities for accountability
- Strong norms against use on civilians
- Counter-proliferation targeting most dangerous actors

### For Medium Proliferation Control Possibility (~25%)

**Invest in control mechanisms:**
- Pursue international agreements even if unlikely
- Strengthen export controls where possible
- Build coalition of nations committed to meaningful human control
- Create verification and monitoring capabilities

## Model Limitations

1. **Unprecedented Pace:** AI-enabled weapons proliferate differently than historical weapons

2. **Dual-Use Complexity:** Hard to model when civilian and military tech are identical

3. **Non-State Actor Uncertainty:** Limited data on how militant groups adopt new technology

4. **Governance Wild Cards:** Major diplomatic breakthroughs or failures could shift trajectories dramatically

## Related Models

- [Autonomous Weapons Escalation Model](/knowledge-base/models/autonomous-weapons-escalation/) - What happens when LAWS are widespread?
- [Flash Dynamics Threshold Model](/knowledge-base/models/flash-dynamics-threshold/) - Speed implications at scale

## Sources

- Carnegie Endowment for International Peace. "Mapping LAWS Development Globally"
- Campaign to Stop Killer Robots. Annual reports
- UN CCW Group of Governmental Experts reports
- SIPRI. "Autonomous Weapons Systems and International Humanitarian Law"
- Academic literature on weapons proliferation dynamics

## Related Pages

<Backlinks client:load entityId="autonomous-weapons-proliferation" />
