---
title: International AI Coordination Game
description: Game-theoretic analysis of international AI governance dynamics between major powers
sidebar:
  order: 31
quality: 3
lastEdited: "2025-12-26"
relatedModels:
  - racing-dynamics-model
  - multipolar-trap-model
  - lab-incentives-model
relatedRisks:
  - concentration-of-power
  - authoritarian-takeover
ratings:
  novelty: 3       # Applies game theory to AI coordination - not novel in isolation
  rigor: 3         # Qualitative game analysis without formal modeling
  actionability: 4 # Specific intervention tracks (Track 1/2/3) and leverage points
  completeness: 4  # Good coverage of players, scenarios, and stability conditions
---

import { DataInfoBox, Backlinks } from '../../../../components/wiki';

<DataInfoBox entityId="international-coordination-game" ratings={frontmatter.ratings} />


## Overview

International AI governance presents a complex coordination problem between major powers - primarily the United States and China, with the European Union, United Kingdom, and other actors playing supporting roles. The structure of this game significantly influences whether humanity achieves safe AI development or races toward catastrophe.

**Central question:** Under what conditions can international coordination on AI safety emerge and remain stable?

## The Players

### Major Powers

**United States**
- Hosts leading AI labs (OpenAI, Anthropic, Google DeepMind, Meta)
- Strong compute infrastructure (NVIDIA, cloud providers)
- Democratic governance, but fragmented policy process
- Oscillating regulatory approaches between administrations

**China**
- Hosts major AI labs (Baidu, Alibaba, Tencent, ByteDance)
- Growing compute capacity, but chip supply constraints
- Centralized governance, can move quickly on policy
- Strategic AI as national priority (Made in China 2025)

**European Union**
- Smaller but significant AI research base
- Leading on regulatory frameworks (AI Act)
- Democratic, but slow consensus-building
- Focus on rights-based approach to AI

**Other actors**
- UK: Punching above weight in research (DeepMind legacy)
- Singapore, UAE, Saudi Arabia: Compute investments
- Japan, South Korea: Industrial AI applications
- India, Brazil: Large markets, growing ambitions

### Interests and Objectives

| Actor | Primary Interests | Secondary Interests |
|-------|-------------------|---------------------|
| **US** | Technological leadership, national security, economic dominance | Democratic values, allied coordination |
| **China** | Technological self-sufficiency, strategic parity, regime stability | Economic development, regional influence |
| **EU** | Values protection, market access, strategic autonomy | Industrial competitiveness, transatlantic alignment |
| **Labs** | Commercial success, regulatory predictability, talent access | Safety (variable commitment), research freedom |

## Game Structure

### The Basic Coordination Game

Two major powers choosing between:
- **Cooperate:** Invest in safety, share information, accept constraints
- **Defect:** Race to capabilities, hoard advantages, minimal safety

**Payoff matrix (stylized):**

|  | China Cooperates | China Defects |
|--|-----------------|---------------|
| **US Cooperates** | (4, 4) Safe AI | (1, 5) China advantage |
| **US Defects** | (5, 1) US advantage | (2, 2) Mutual racing |

**Key features:**
- Mutual cooperation is Pareto-optimal but not stable
- Unilateral defection is tempting (first-mover advantage)
- Mutual defection is stable but suboptimal
- Classic prisoner's dilemma structure

### Complications

**Asymmetric Information:**
- Each side uncertain about other's capabilities
- Classified research creates fog of war
- Incentives to exaggerate or conceal progress

**Multiple Dimensions:**
- Compute: Hardware, data centers, chip manufacturing
- Algorithms: Research, training techniques, architectures
- Applications: Deployment, integration, use cases
- Safety: Alignment research, evaluations, safeguards

**Time Dynamics:**
- Early stages: More room for cooperation
- Near-AGI: Racing pressure intensifies
- Post-AGI: Game structure changes fundamentally

## US-China Dynamics

### Sources of Competition

**Technological nationalism:**
- AI as "commanding heights" of 21st century
- Zero-sum framing in political discourse
- Military applications (autonomous weapons, ISR)
- Economic competition (automation, services)

**Ideological dimension:**
- Democratic vs. authoritarian models
- Surveillance capitalism vs. state surveillance
- Human rights concerns (Xinjiang, social credit)
- Information control and censorship

**Strategic distrust:**
- Decades of geopolitical competition
- Taiwan tensions
- Economic decoupling pressures
- Lack of direct communication channels

### Sources of Common Interest

**Shared risks:**
- Catastrophic AI outcomes harm both
- Extinction is not in anyone's interest
- Arms race dynamics hurt both sides
- Economic disruption affects global economy

**Mutual benefits:**
- Aligned AI is a global public good
- Safety research can be shared
- Regulatory coordination reduces costs
- Scientific collaboration accelerates progress

**Precedents:**
- Nuclear arms control achieved despite Cold War
- Climate cooperation (imperfect but existent)
- Pandemic cooperation (variable success)
- Space cooperation (ISS model)

### Asymmetries

**US advantages:**
- Current capability lead
- Stronger semiconductor ecosystem
- Allied coordination (Five Eyes, Quad, AUKUS)
- Private sector dynamism
- Talent attraction

**Chinese advantages:**
- Data availability (population scale, less privacy constraint)
- Faster policy implementation
- State funding capacity
- Long-term planning horizon
- Control over domestic companies

**Implications:**
- US may prefer to maintain lead through competition
- China may prefer coordination to catch up
- Both may miscalculate relative position

## First-Mover vs. Coordination

### First-Mover Advantages

**Arguments for racing:**
1. Winner shapes AI development trajectory
2. Second place may be locked out permanently
3. National security requires dominance
4. Coordination is naive about adversary intentions
5. Lead provides leverage to set global norms

**Problems with racing:**
1. Cuts corners on safety
2. Accelerates timeline before safety is solved
3. Creates arms race dynamics
4. Reduces trust for later coordination
5. May not actually achieve lasting advantage

### Coordination Benefits

**Arguments for coordination:**
1. Reduces catastrophic risk for all
2. Allows more time for safety research
3. Creates stable equilibrium
4. Enables resource sharing
5. Avoids duplicative costs

**Problems with coordination:**
1. Verification is difficult
2. Defection risk is high
3. Domestic political costs
4. May slow beneficial applications
5. May not include all relevant actors

### The Coordination-Competition Spectrum

Reality is not binary. Options include:

**Full Racing** (-1)
- No constraints
- Minimal communication
- Maximum competition

**Competitive Coexistence** (0)
- Some communication
- Limited coordination on worst outcomes
- Continued capability competition

**Managed Competition** (+0.5)
- Regular dialogue
- Red lines on most dangerous applications
- Cooperation on safety research

**Deep Coordination** (+1)
- Binding agreements with verification
- Shared safety standards
- Joint governance mechanisms

**Current state:** Between -1 and 0, moving negative

## Treaty and Agreement Stability

### Conditions for Stable Agreements

**Verification:**
- Can defection be detected?
- How quickly?
- With what confidence?

**Enforcement:**
- What are the penalties for defection?
- Are they credible?
- Can punishment be targeted?

**Iteration:**
- Is the game repeated?
- Is there a shadow of the future?
- Can reputation mechanisms work?

### Verification Challenges

**What can be verified:**
- Large compute clusters (satellite observation, power consumption)
- Major deployments (public products)
- Published research (with time lag)
- Chip sales and transfers

**What cannot be verified:**
- Algorithmic advances
- Internal capability levels
- Safety practices
- Intent and plans

**Implication:** Any agreement must focus on verifiable dimensions, likely compute governance.

### Enforcement Mechanisms

**Economic:**
- Trade sanctions
- Technology export controls
- Financial restrictions
- Investment screening

**Diplomatic:**
- Alliance coordination
- International isolation
- Reputation costs
- Normative pressure

**Technical:**
- Compute governance (kill switches)
- Hardware backdoors
- Standard setting

**Limits:**
- Major powers are hard to sanction
- Mutual dependencies create hesitation
- Enforcement can escalate conflict

### What Makes Agreements Stable?

**Self-enforcing structure:**
- Mutual gains from compliance
- Costs of defection exceed benefits
- Graduated response to violations

**Institutional support:**
- Monitoring organizations
- Regular review mechanisms
- Dispute resolution processes

**Domestic politics:**
- Leaders can sell agreement at home
- Interest groups benefit from compliance
- Nationalism doesn't override cooperation

## Scenario Analysis

### Scenario 1: Successful Coordination (15% probability)

**Path:**
1. Major AI incident raises salience globally
2. Track 2 diplomacy establishes common ground
3. Bilateral US-China framework on AI safety
4. Multilateral expansion (G7+, UN framework)
5. Verification mechanisms prove workable

**Requirements:**
- Crisis that demonstrates shared risk
- Leadership willing to take political risk
- Technical verification solutions
- Domestic political support

**Outcome:** Slower, safer AI development trajectory

### Scenario 2: Competitive Coexistence (35% probability)

**Path:**
1. Continued competition, but avoiding worst outcomes
2. Informal red lines on military AI
3. Some scientific exchange continues
4. Parallel development in both blocs
5. Gradual norm development

**Requirements:**
- No major crises that escalate
- Continued mutual dependency
- Lab-level safety practices hold
- No technological surprise

**Outcome:** Moderate racing, elevated risk, not catastrophic

### Scenario 3: Accelerating Race (35% probability)

**Path:**
1. Perceived breakthrough by one side
2. Panic response by other
3. Racing dynamics intensify
4. Safety cuts to maintain pace
5. Coordination becomes impossible

**Triggers:**
- Major algorithmic advance
- Compute breakthrough
- Geopolitical crisis (Taiwan)
- Collapse of existing channels

**Outcome:** Rapid capability growth, minimal safety, high catastrophic risk

### Scenario 4: Decoupled Worlds (15% probability)

**Path:**
1. Full technological decoupling
2. Separate AI ecosystems develop
3. No coordination possible
4. Parallel development with no safety alignment
5. Eventual collision or divergent outcomes

**Drivers:**
- Full chip export ban
- Data sovereignty enforced
- Alliance structures harden
- No remaining points of contact

**Outcome:** Unknown - depends on which system develops first

## Intervention Points

### Track 1 (Government-to-Government)

**Bilateral mechanisms:**
- Direct leader engagement
- AI-specific dialogue channels
- Incident prevention agreements
- Red lines on military applications

**Multilateral mechanisms:**
- G7/G20 AI frameworks
- UN AI governance process
- OECD AI principles
- Regional arrangements

### Track 2 (Expert and Lab)

**Scientific exchange:**
- Joint safety research projects
- Shared evaluation frameworks
- Conference participation
- Publication norms

**Lab-to-lab coordination:**
- Safety practice sharing
- Evaluation collaboration
- Voluntary commitments
- Information sharing on incidents

### Track 3 (Civil Society)

**Epistemic work:**
- Shared understanding of risks
- Common vocabulary
- Research translation
- Public education

**Advocacy:**
- Pressure for coordination
- Accountability mechanisms
- International campaigning
- Media engagement

### Key Leverage Points

1. **Compute governance:** Most verifiable dimension, focus international attention here
2. **Safety research sharing:** Low cost, high benefit, builds trust
3. **Incident communication:** Hot lines for AI incidents, reduce accident risk
4. **Evaluation standards:** Common benchmarks enable monitoring
5. **Talent policy:** Immigration and exchange shape development location

## Model Limitations

### Assumptions

1. **Rational actors:** Governments may be driven by ideology, domestic politics, or error
2. **Bilateral focus:** Other actors (EU, labs, researchers) matter significantly
3. **State-centric:** Labs and individuals have agency that crosses borders
4. **Static preferences:** Interests and constraints evolve over time

### Missing Dynamics

1. **Domestic politics:** Elections, factional conflict, public opinion
2. **Technology surprise:** Breakthroughs can change game structure
3. **Third parties:** Other actors may defect or enable coordination
4. **Non-state actors:** Labs, researchers, civil society have independent agency

### Empirical Uncertainties

- How strong is the first-mover advantage actually?
- Can AI capabilities be verified at all?
- Will domestic politics permit cooperation?
- What is the actual capability gap?

## Open Questions

1. **Is meaningful verification possible?** Can we monitor AI development sufficiently to enable agreements?
2. **What triggers would enable cooperation?** What kind of crisis or opportunity could shift dynamics?
3. **Can labs lead where governments cannot?** Private coordination as alternative to state coordination?
4. **Is the game actually iterated?** Or is AGI a one-shot game that changes everything?
5. **What role for middle powers?** Can EU, UK, or others facilitate coordination?

## Related Models

- [Racing Dynamics Model](/knowledge-base/models/racing-dynamics/) - Lab-level competition analysis
- [Multipolar Trap Model](/knowledge-base/models/multipolar-trap/) - Coordination failure mechanisms
- [AI Lab Incentives Model](/knowledge-base/models/lab-incentives-model/) - Private sector dynamics

## Sources

- Allison, Graham. *Destined for War* (2017) - Thucydides Trap framework
- Dafoe, Allan. "AI Governance: A Research Agenda" (2018)
- Kissinger, Henry et al. *The Age of AI* (2021)
- Schelling, Thomas. *The Strategy of Conflict* (1960)
- Ding, Jeffrey. "Deciphering China's AI Dream" (2018)

## Related Pages

<Backlinks client:load entityId="international-coordination-game" />
