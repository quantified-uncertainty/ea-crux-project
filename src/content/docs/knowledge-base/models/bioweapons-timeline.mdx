---
title: AI-Bioweapons Timeline Model
description: Projecting when AI capabilities might meaningfully increase bioweapons risks
sidebar:
  order: 12
quality: 3
lastEdited: "2025-12-25"
---

import { DataInfoBox, Backlinks } from '../../../../components/wiki';

<DataInfoBox entityId="bioweapons-timeline" />

## Overview

This model projects when AI capabilities might cross thresholds that meaningfully change bioweapons risk. Rather than asking "is AI dangerous now?", it asks "when might it become dangerous, and under what conditions?"

## Key Thresholds

### Threshold 1: Knowledge Democratization
**Definition:** AI provides bioweapons-relevant knowledge more effectively than existing sources to non-experts.

**Current status:** Partially crossed—LLMs know relevant information but guardrails and knowledge gaps limit utility.

**Projection:** Likely fully crossed by 2025-2027 as models become more capable and open-source versions proliferate.

### Threshold 2: Synthesis Assistance
**Definition:** AI meaningfully helps with actual pathogen synthesis, not just theoretical knowledge.

**Current status:** Not crossed—this requires integration with lab automation, biological design tools, and hands-on guidance.

**Projection:** 2027-2032, contingent on:
- Progress in biological design tools
- Automated lab systems
- Integration between AI systems

### Threshold 3: Novel Agent Design
**Definition:** AI enables creation of pathogens with properties not found in nature.

**Current status:** Not crossed, but concerning research directions exist.

**Projection:** 2030-2040, highly uncertain. May require:
- Significant advances in protein engineering AI
- Better understanding of pathogenesis
- Integration across multiple AI systems

### Threshold 4: Full Attack Automation
**Definition:** AI significantly assists with all phases from design through deployment.

**Current status:** Far from crossed.

**Projection:** 2035+, very uncertain.

## Scenario-Based Projections

### Scenario A: Rapid AI Progress
*AI capabilities advance faster than expected, biosecurity lags*

| Year | Threshold Crossed | Risk Level |
|------|-------------------|------------|
| 2025 | Knowledge democratization | Elevated |
| 2027 | Synthesis assistance | High |
| 2030 | Novel agent design | Very High |
| 2035 | Full automation possible | Critical |

**Probability estimate:** ~15-25%

### Scenario B: Gradual Progress, Biosecurity Keeps Pace
*Capabilities advance but so do countermeasures*

| Year | Threshold Crossed | Risk Level |
|------|-------------------|------------|
| 2026 | Knowledge democratization | Moderate |
| 2030 | Synthesis assistance | Elevated |
| 2040 | Novel agent design | High |
| 2050+ | Full automation possible | Uncertain |

**Probability estimate:** ~40-50%

### Scenario C: Successful Governance
*Strong AI governance prevents highest-risk applications*

| Year | Threshold Crossed | Risk Level |
|------|-------------------|------------|
| 2026 | Knowledge democratization | Moderate |
| 2035+ | Synthesis assistance (limited) | Elevated |
| Delayed | Novel agent design | Uncertain |

**Probability estimate:** ~20-30%

### Scenario D: Black Swan
*Unexpected breakthrough or catastrophic failure*

Difficult to timeline by definition. Could accelerate any threshold by 5+ years.

**Probability estimate:** ~10-15%

## Key Capability Milestones to Watch

### Near-term (2025-2027)
- [ ] Open-source models match frontier models on biology benchmarks
- [ ] Protein structure prediction achieves high accuracy on novel folds
- [ ] Lab automation becomes accessible to small actors
- [ ] AI-designed molecules enter clinical trials

### Medium-term (2027-2032)
- [ ] AI systems can design functional proteins de novo
- [ ] Generative biological models reach high fidelity
- [ ] Closed-loop AI-lab integration demonstrated
- [ ] DNA synthesis costs drop below $0.01/base

### Long-term (2032+)
- [ ] AI can model complex biological systems end-to-end
- [ ] Autonomous biological research demonstrated
- [ ] Synthetic cells become routine

## Intervention Windows

| Intervention | Optimal Window | After Window |
|--------------|----------------|--------------|
| LLM guardrails | Now - 2026 | Harder to implement, open-source proliferation |
| DNA synthesis screening | Now - 2028 | May be evaded by novel synthesis methods |
| International coordination | Now - 2027 | Harder after major incident |
| Countermeasure R&D | Always | Catch-up is possible but costly |
| Compute governance | Now - 2026 | Training runs become distributed |

## Uncertainty Ranges

For each threshold, here are probability distributions for when it might be crossed:

### Knowledge Democratization
- **5th percentile:** Already crossed
- **Median:** 2025
- **95th percentile:** 2028
- **Distribution shape:** Left-skewed (probably soon)

### Synthesis Assistance
- **5th percentile:** 2026
- **Median:** 2029
- **95th percentile:** 2040
- **Distribution shape:** Wide, fat-tailed

### Novel Agent Design
- **5th percentile:** 2028
- **Median:** 2035
- **95th percentile:** 2060+
- **Distribution shape:** Very wide, high uncertainty

## Warning Indicators

What would update us that timelines are accelerating?

| Indicator | Interpretation |
|-----------|----------------|
| AI labs flag biosecurity concerns more frequently | Internal evals showing uplift |
| Biosecurity incidents involving AI | Thresholds being crossed |
| Rapid progress on protein engineering | Technical barriers dropping |
| State investment in AI+bio weapons | Geopolitical concern |
| Academic papers retracted for dual-use | Knowledge becoming dangerous |

## Model Limitations

1. **Unknown unknowns** - Breakthroughs are inherently unpredictable
2. **Interaction effects** - Capabilities may combine non-linearly
3. **Adversarial dynamics** - Attackers adapt to defenses
4. **Geopolitical factors** - Wars, treaties, etc. could shift timelines dramatically
5. **Definition dependence** - "Meaningful increase" is subjective

## Summary

**Central estimate:**
- Significant AI-bioweapons risk by late 2020s to early 2030s
- Current window (2024-2027) is critical for establishing governance
- High uncertainty in all projections

**Robust conclusions:**
1. Knowledge democratization is imminent or already happening
2. Synthesis assistance is further out but not remote
3. Novel agent design is genuinely uncertain
4. Countermeasures and biosecurity matter at all timelines

## Related Models

- [Attack Chain Model](/knowledge-base/models/bioweapons-attack-chain/) - Current risk decomposition
- [AI Uplift Model](/knowledge-base/models/bioweapons-ai-uplift/) - Current state of AI contribution

## Sources

- Epoch AI capability projections
- Metaculus forecasts on AI milestones
- CNAS biosecurity timeline analysis
- Expert elicitation from biosecurity researchers

## Related Pages

<Backlinks client:load entityId="bioweapons-timeline" />
