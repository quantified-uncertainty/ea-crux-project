---
title: Key Uncertainties & Cruxes
description: Central disagreements and uncertainties that shape views on AI safety
sidebar:
  order: 0
---

import { InfoBox, Section, Tags, EntityCards, EntityCard } from '../../../../components/wiki';

<InfoBox
  type="crux"
  title="Key Uncertainties"
  customFields={[
    { label: "Purpose", value: "Identify where reasonable people disagree" },
    { label: "Value", value: "Focus research and debate on what matters most" },
    { label: "Approach", value: "Empirical questions that could update views" },
  ]}
/>

## What Are Cruxes?

A **crux** is a question where:
1. Different answers lead to significantly different conclusions or priorities
2. The question is (at least somewhat) empirically resolvable
3. Reasonable people currently disagree on the answer

Identifying cruxes helps:
- Focus research on the most decision-relevant questions
- Enable productive disagreement (find what actually matters)
- Track how evidence should update views over time

---

## Cruxes by Domain

### Risk Assessment Cruxes

Key uncertainties about which risks matter most and how severe they are:

| Domain | Page | Key Questions |
|--------|------|---------------|
| **[Accident Risks](/knowledge-base/cruxes/accident-risks/)** | Technical failures, misalignment | Will we get warning signs? Can we verify alignment? |
| **[Misuse Risks](/knowledge-base/cruxes/misuse-risks/)** | Intentional harm, weapons | How much does AI amplify malicious actors? |
| **[Structural Risks](/knowledge-base/cruxes/structural-risks/)** | Concentration, racing, lock-in | Are racing dynamics inevitable? |
| **[Epistemic Risks](/knowledge-base/cruxes/epistemic-risks/)** | Truth, knowledge, trust | Can verification keep pace with generation? |

### Solution Cruxes

Key uncertainties about what interventions work:

| Domain | Page | Key Questions |
|--------|------|---------------|
| **[Solutions](/knowledge-base/cruxes/solutions/)** | Epistemic & coordination tools | Can AI defense match AI offense? |

---

## Cross-Cutting Cruxes

Some questions cut across multiple domains:

### Timelines
- When will transformative AI arrive?
- How much does this affect which interventions matter?

### Alignment Difficulty
- Is alignment a hard technical problem or an engineering challenge?
- Do current techniques scale?

### Coordination
- Can labs/governments coordinate effectively?
- Do racing dynamics prevent adequate safety margins?

### Warning Signs
- Will we get clear signals before catastrophic capabilities?
- Can evaluations provide meaningful safety guarantees?

---

## How to Use This Section

**For prioritization:**
- Identify which cruxes most affect your views
- Focus learning on resolving your key uncertainties

**For research:**
- Target empirical work at resolvable cruxes
- Design studies that could shift community views

**For dialogue:**
- Find where you actually disagree with others
- Avoid arguing past each other on downstream conclusions

<Section title="Related Topics">
  <Tags tags={[
    "Cruxes",
    "Key Uncertainties",
    "Disagreements",
    "Research Priorities",
    "Decision-Making",
  ]} />
</Section>
