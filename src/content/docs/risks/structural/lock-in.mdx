---
title: Lock-in
description: Permanent entrenchment of values, systems, or power structures
sidebar:
  order: 2
---

import { InfoBox, EntityCard, EntityCards, Tags, Sources, Section } from '../../../../components/wiki';

<InfoBox
  type="risk"
  title="Lock-in"
  severity="catastrophic"
  likelihood="Medium"
  timeframe="Medium to Long-term"
  customFields={[
    { label: "Type", value: "Structural" },
    { label: "Key Feature", value: "Irreversibility" },
  ]}
/>

## Overview

Lock-in refers to the permanent entrenchment of values, systems, or power structures in ways that are extremely difficult or impossible to reverse. AI could enable lock-in by giving certain actors the power to entrench their position, by creating systems too complex to change, or by shaping the future according to early decisions that become irreversible.

What makes lock-in concerning is its permanence: mistakes locked in at a critical period could persist indefinitely.

## Types of Lock-in

Value lock-in occurs when particular values get embedded permanently. An AI system optimizing for specific objectives might reshape the world around those objectives, making alternatives impossible. Or a regime might use AI to enforce an ideology so thoroughly that alternatives become unthinkable.

Political lock-in happens when a government or system becomes permanently entrenched through AI-enabled control. Historical empires eventually fell; AI-enabled surveillance and control might make modern autocracies stable indefinitely.

Technological lock-in occurs when an AI architecture or approach becomes so embedded in infrastructure that switching becomes prohibitively expensive. Suboptimal or dangerous designs might persist because the transition costs are too high.

Economic lock-in happens when AI-enabled monopolies or economic structures become permanent features, preventing correction through normal market mechanisms.

## Why AI Increases Lock-in Risk

AI provides tools for enforcement that previous technologies didn't. Comprehensive surveillance, predictive control, and autonomous systems could make resistance to entrenched systems effectively impossible.

AI speed and scale makes early decisions more consequential. An AI system that starts optimizing in a particular direction might reshape the world faster than humans can redirect it.

AI complexity creates path dependence. As AI becomes embedded in critical systems, changing course becomes harder. Dependencies accumulate.

## Historical Parallels

History contains partial lock-ins. Writing systems, once established, persisted for millennia. Political boundaries established in colonial periods persist today. But these were never truly permanent—change was possible, just costly.

The concern with AI is that true permanence might become possible. If an entity has overwhelming power and the ability to maintain it indefinitely, historical precedents for change don't apply.

## Relationship to Existential Risk

Lock-in of bad outcomes is sometimes considered a category of existential risk distinct from extinction. A future locked into perpetual suffering, oppression, or stagnation might be as bad as no future at all.

Toby Ord uses the term "dystopian lock-in" for scenarios where humanity survives but in a permanently degraded state. AI-enabled totalitarianism is one example.

## The Importance of the Current Period

If lock-in is possible, the period when values and structures are being established is crucial. Early decisions about AI development, governance, and deployment may have irreversible consequences.

This suggests urgency: getting AI development right during this window may matter far more than getting it right would in a world where course correction remained possible.

## Prevention

Avoiding premature lock-in means keeping options open, maintaining diversity of approaches, and ensuring that no single actor can make irreversible choices for everyone.

Preserving flexibility involves building AI systems that can be modified, redirected, or shut down—maintaining human agency over the trajectory of AI development.

Democratic legitimacy for any major decisions reduces the risk that a small group locks in their preferences.

Robustness to error means designing systems that can survive mistakes without permanent damage.

<Section title="Related Topics">
  <Tags tags={[
    "Existential Risk",
    "Irreversibility",
    "Path Dependence",
    "AI Governance",
    "Long-term",
  ]} />
</Section>

<Section title="Related Entries">
  <EntityCards>
    <EntityCard
      id="concentration-of-power"
      category="risk"
      title="Concentration of Power"
      description="Who might lock things in"
    />
    <EntityCard
      id="authoritarian-tools"
      category="risk"
      title="Authoritarian Tools"
      description="Political lock-in mechanisms"
    />
    <EntityCard
      id="corrigibility-failure"
      category="risk"
      title="Corrigibility Failure"
      description="AI systems resisting change"
    />
  </EntityCards>
</Section>

<Sources sources={[
  { title: "The Precipice", author: "Toby Ord", date: "2020" },
  { title: "What We Owe the Future", author: "Will MacAskill", date: "2022" },
  { title: "Existential Risk and the Future of Humanity", url: "https://existential-risk.org/" },
]} />
